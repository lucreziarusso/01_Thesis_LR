<!DOCTYPE html PUBLIC>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="viewport" content="initial-scale=1, maximum-scale=1">
  <title>THESIS</title>

  <!-- Metadata -->
  <meta name="robots" content="noindex, nofollow">
  <meta name="author" content="" />
  <meta name="copyright" content="" />

  <!-- Paged.js -->
  <link rel="stylesheet" type="text/css" href="css/pagedjs/pagedjs.css">
  <link rel="stylesheet" type="text/css" href="css/reset.css">
  <!-- <link rel="stylesheet" type="text/css" href="css/pagedjs/interface/baseline.css"> -->
  <script src="js/paged.polyfill.js"></script>
  <script src="js/handlers.js"></script>
  <!-- <script src="js/footnotes.js"></script> -->

  <!-- Style -->
  <link rel="stylesheet" type="text/css" href="css/style.css">

  <!-- Fonts -->
  <!-- <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=EB+Garamond&display=swap" rel="stylesheet"> -->

</head>

<body>


  <!-- YOUR CONTENT HERE -->

  <div class="wrapper">

    <div class="one">
      <aside>
        <div class="footnote"><span class="fnnum">[1]</span>Graphisme En France 2012 : Code <> Outils <>
              Design, trans. Lucrezia Russo (Paris: Centre national des arts plastiques, 2012).</div>
        <div class="footnote"><span class="fnnum">[2]</span> idem, 5.</div>
        <span class="footnote"><span class="fnnum">[3]</span> idem, 6.</span><br>
        <span class="footnote"><span class="fnnum">[4]</span> idem, 9.</span><br>
        <span class="footnote"><span class="fnnum">[5]</span> idem, 8.</span><br>
        <span class="footnote"><span class="fnnum">[6]</span> 2017 CAST Symposium BEING MATERIAL: Ben Fry and Casey
          Reas. www.youtube.com<br>/watch?v=9BtqBjGEpA0.</span><br>
        <span class="footnote"><span class="fnnum">[7]</span> ibid.</span><br>
        <span class="footnote"><span class="fnnum">[8]</span> CAST Symposium BEING MATERIAL.</span><br>
        <span class="footnote"><span class="fnnum">[9]</span> Casey Reas, “Thoughts on Software for the Visual Arts,”
          Medium, January 27, 2019, https://medium.com /@REAS/thoughts-on- software-for-the -visual-arts-
          690ea7bfc8b6.</span><br>

      </aside>
    </div>


    <div class="two">

      <section>

        <div class="oneCol">
          <h1>Introduction</h1>
        </div>

        <div class="twoCol">
          Over the last three decades, the exponential development of technology has impacted all creative practices
          and
          has radically changed graphic design perspectives. The revolution brought about by the rise of the personal
          computer, particularly the release of the first Macintosh in 1984, created new opportunities for graphic
          design
          research and production, opening the path to methodological and esthetical experimentations. Nevertheless, the
          transition between the two centuries marked a pivot and revealed the exhaustion of that momentum, which
          mutated
          into a manifest crisis of creative methodologies. Companies like Apple, Adobe, and, years later, Google have
          been the driving force behind the technological revolution in design. However, in their effort to provide
          access
          to easy-to-use computers, interfaces, and tools, they have participated in the standardization of design
          esthetics, and fostered the commodification of design culture instead of its democratization.<br>
          In 2012, Kevin Donnot published the article “Code = design,” <span class="fnnum">[1]</span> an excerpt of his
          master’s thesis “Outils
          numériques et design graphique” (Digital Tools and Graphic Design). The essay questions the tools largely
          employed in the graphic design practice and, by extension, the practice itself. Restrained by the limitations
          of
          the massified software and submitted to the monopolization of devices that occurred in the early 2000s, the
          graphic designer must reclaim, Donnot stated, his status as a craftsperson and reappropriate the tools of
          creation. <span class="fnnum">[2]</span> Indeed, the standardization of the tools would translate to a
          normalization of graphic production and
          its esthetic. <span class="fnnum">[3]</span> To foster originality the graphic designer must become the maker
          of the creative tools.
          Programming and free software seem a possible alternative to reclaim this active role: “The interest of the
          free
          software [is that] the designer can integrate new functions and, above all, understand how the software works.
          Then, s/he is not lowered to a role of ‘user’ or ‘consumer’ and condemned to technical passivity. S/he moves
          from the status of consumer to the one of creator.” <span class="fnnum">[4]</span>
          Ten years after its release, Donnot mentioned Processing as being one of the programming languages and
          environments, within the free software movement, which represented an interesting alternative for graphic
          design: “The software proposes a new space for visual experimentation where the design is controlled by code.
          […] This alternative approach implies alternative creative processes and, therefore, alternative graphical
          propositions.” <span class="fnnum">[5]</span> Finally, Processing had crossed the Atlantic and was recognized
          as ambassador of the free and
          open source software movement, and as legitimate tool for the graphic design practice.<br><br>

          Conceived at the Massachusetts Institute of Technology (MIT) by Casey Reas and Ben Fry and built on the
          shoulders of prestigious predecessors such as Muriel Cooper and John Maeda, the first version of Processing
          was
          released in 2001. An easy-to-use, accessible coding language and programming environment, Processing was
          created
          to provide an educational tool for learning the graphic design principles, such as color and composition,
          through the medium of computation. <span class="fnnum">[6]</span> Intended for artists and designers, Reas and
          Fry’s proposition fostered the
          idea of “learning to create software” as opposed to “learning to use software,” suggesting a practical
          solution
          to the crisis of design methodologies of the late 1990s. <span class="fnnum">[7]</span> From the onset,
          Processing was quickly adopted by
          professionals who embraced its potential as a modular, expandable, and customizable kit. <span
            class="fnnum">[8]</span> Its auto-productive
          methodology echoed Do It Yourself (DIY) and hackers’ approaches and it opened the path to a renewal of the
          crafts in the design practice, resulting in a hybridization of analog and digital methods of productions.<br>
          Nevertheless, the core idea of Processing is even more radical, and its moral extent that “emerged within the
          culture of free software” <span class="fnnum">[9]</span> defines its approach and “differentiates [it] from
          proprietary, consumer-driven
          software.” Processing stands alongside the free/libre and open source software ideology and promotes the ideas
          of freedom and accessibility as essential. This position distances the project from purely esthetic
          considerations, adding a moral dimension in extending methodology to ideology. In the last decade, a community
          has grown. The work done by the community has provided new meanings to the expression “open source,” and has
          fostered a new vision of shared and decentralized collaboration, in fields that not only deal with software
          development.<br><br>

          Within this context, this thesis investigates, through the prism of graphic design, how Processing and the
          community built around it have transformed the design field and influenced the current generation of
          designers.
          Providing new perspectives to expand creativity and stand against the normalization of design imposed by
          design
          monopolies, Processing can be considered a pivot, this research postulates, in the dialectic opposition
          between
          the free open source and the start-up cultures, both interlaced within the graphic design field.
          The first chapter defines and contextualizes the opposition between start-up and free open source cultures,
          which arose in Silicon Valley and MIT between the 1970s and the beginning of the new century. The analysis of
          cases such as Apple Computer, Adobe Systems, and Google Design exemplifies the paradox of the start-up model,
          highlighting its metamorphosis from a counterculture into a monopoly. The review of core texts by the leading
          actors of the hacker, free software, and open source movements clarifies the misconception of free and open
          source culture and recognizes Processing as an advocate for a free and decentralized approach.
          The second part of this research focuses on Processing and the community developed around it over the last
          twenty years. From Muriel Cooper and John Maeda to Casey Reas and Ben Fry, this chapter first describes
          Processing’s origins at MIT. By analyzing the platform’s main components—language, environment, community—the
          chapter examines how Processing has expanded the concept of accessibility, questioning its economic, social,
          and
          political aspects, and has fostered values of inclusion as a critical part of the project.
          Finally, this research describes in its third chapter how the free open source culture and the system of
          values
          fostered by Processing influenced contemporary designers, contributing to the emergence of new patterns in the
          graphic design field. Through the reappropriation of the creative tools, contemporary designers distance their
          productions from standardized esthetics and reveal alternative methodologies that encompass values of
          accessibility and inclusion as a central part of their work. These methodologies, including the hybridization
          of
          production tools, DIY distribution methods, participatory generative design, and the use of cyberspace as a
          free
          framework, are valid propositions for a practice renewal based on responsibility and flexibility.
          To solve the perpetual struggle of graphic designers’ position, often tugged between radical polarities—design
          research on one side and design industry on the other—this thesis highlights alternative perspectives
          encompassing the acceptance of the profession’s paradox and the awareness of the designers’ responsibility in
          contemporary society.
        </div>
      </section>
    </div>

      <div class="one">
        <aside>
          <div class="footnote"><span class="fnnum">[10]</span>2016_All Over_interview Vera Molnar, trans. Lucrezia
            Russo,
            2016, https://vimeo.com/384470661.</div>
          <div class="footnote"><span class="fnnum">[11]</span>MuDA, Vera Molnar: Randomness, 2019,
            https://vimeo.com/372579247.</div>
        </aside>
      </div>

      <div class="two">
        <section>
          <div class="oneCol">
            <h1> 1. Start-up vs. Free Open Source: Contrasting Cultures</h1>
          </div>

          <div class="twoCol">
            Graphic Design history cannot be dissociated from the technological evolution of tools: from the invention
            of
            the movable-type printing press, that shaped a new relationship to alphabets and, therefore, to typography,
            till
            the creation of the offset printing or the photocopy machine, which liberated the production and
            distribution
            of
            artist books and fanzines, new design esthetics and methodologies have always been empowered by new
            technological devices.
            Computational machines, the precursors of personal computers, joined the list of tools that have informed
            and
            reformed the way artists and designers conceived and produced images. By the 1970s, we observed a rising
            interest in merging art and mathematics through the medium of computation. Artists such as Vera Molnár,
            Manfred
            Mohr, and Frieder Nake pioneered the exploration of algorithmic thinking as a practical methodology for the
            arts. In a recent interview, Vera Molnár reiterated her approach: “In order to detect this extraordinary
            moment
            when the art arises, we do not have enough time and strength to craft it. It would mean to make millions and
            billions of variations. […] Here, you have a slave that follows your wishes. [The computer] allows you to
            materialize very quickly your visual thoughts which you could not have created because of lack of time or
            strength, or visual acuteness.” Working with computation, Molnár pursued a part of the research developed by
            artists like Sol Lewitt, based on conceiving instructions to create a work of art. Giving instructions to
            the
            machine through code and randomizing some variables, she was, therefore, expanding intuition and enriching
            her
            senses: “There is a thing that can replace intuition. It’s randomness. Because […] it will show you billions
            of
            possibilities of which, with your limited imagination, you could not have thought of.”
            The concept of expanding the potential of creation, using computers and code, is not limited to this radical
            artistic research. Mirroring the niche of computational art, the graphic design scene of central Europe of
            the
            1960s developed design research that explored the potential of computation. Karl Gerstner, a prominent
            figure
            of the Swiss graphic design scene of post-WWII, was one of the first graphic designers who foresaw the
            opportunities brought by computers for a rational and functional graphic design production. In 1963, he
            published Designing Programmes, in which he compiled his efforts for automatizing processes and applying
            scientific methodologies to design. The designer needed a set of rules to select and arrange the different
            design components (typography, images, color). The computer could help create systems that enlarge the range
            of solutions, within which the designer could identify the best one.
            If the work of Gerstner or Molnár was situated at a time when computational machines were essentially
            accessible for scientific or military research, the release of the first Macintosh in 1984 was a pivot
            towards
            the extension of access to computers for graphic designers, and, in the following years, for a bigger
            audience.
            The American graphic designer April Greiman—who did part of her studies in Basel in the 1970s and was
            immersed
            in the swiss graphic design approach—was one of the first designers to openly embrace the opportunities
            created by the Macintosh. Interviewed by the magazine Emigre in 1988, she echoed Vera Molnár: “What I
            experience is rather than just doing something quickly, we’re looking at more possibilities. Instead of
            doing
            more work, we are seeing more options. […] With the Mac, once the information is stored, you can just look
            at
            seventy-two thousand variations. And then the accidents happen, and you say, ‘Oh that’s so much better, why
            don’t you go that way?’”
            The iteration of graphic results offered by the machine was promoted as a sustainable methodology for
            design.
            Furthermore, Greiman adopted the esthetical language of the computer as a new opportunity for graphic design
            expression: the pixel, the raster of the screen, transparency and superposition, as well as the simultaneous
            presence of visual elements became core elements of her production. These new esthetics could, according to
            Greiman, empower personal and collective manifestation: “Everybody is visual; it’s in the collective soul,
            and
            the Mac will empower and help a lot of these people to express themselves. I like the idea that so many
            people
            will have a common language […] And this tool has its own language!”
            Despite this optimistic vision, we witnessed, starting the mid-1990s, a slow but consistent shift towards a
            different use of the computer. If it was true that in the late 1980s computers were considered tools
            submitted
            to human beings to expand perception and production, during the following decade this trend faded away. In
            the
            early 2000s, it resulted in the massification of visual language’s esthetics due to a standardization of the
            tools and, therefore, of the graphic design practice.
            So, what happened between the end of the 1980s and the beginning of the 2000s? What were the reasons for the
            shift of the graphic design practice towards standardized methodologies? Radical design research based on
            the
            exploration of computer depth through the medium of computation was still pursued in institutions such as
            MIT.
            Nevertheless, in the 1990s, the professional graphic design field was deeply impacted by the rise of the
            “What-You-See-Is-What-You-Get” (WYSIWYG) interfaces that became popular as a way of emancipating oneself
            from
            the required understanding of the machine to be able to make design, allowing a more intuitive approach to
            graphic composition. Two opposite approaches developed in parallel and drew the main characteristics of what
            this thesis has defined as “start-up and free open source cultures.” In the following sections, we clarify
            their origins and highlight their radical opposition that resulted, at the very beginning of twenty-first
            century, with the birth of Processing.

            <h2>1.1 From Counterculture to Monopoly: A Silicon Valley Story</h2>
            Narrowing down the geographical context in which the technological evolution of the end of the twentieth
            century occurred, we observe that devices and programs massively employed, on a worldwide scale, for graphic
            design production were created in the Silicon Valley. The binomial Apple Computer and Adobe Systems
            intersected in this economic region located in Northern California in the United States. This region,
            pervaded
            by the “Californian Ideology,” represented the biggest cultural paradox of modern history, and the
            contemporary design’s culture has been molded mirroring this paradox.

            <br><br>

            <p class="quote">The Californian Ideology promiscuously combines the free-wheeling spirit of the hippies and
              the
              entrepreneurial zeal of the yuppies. This amalgamation of opposites has been achieved through a profound
              faith
              in the emancipatory potential of the new information technologies. In the digital utopia, everybody will
              be
              both hip and rich. Not surprisingly, this optimistic vision of the future has been enthusiastically
              embraced
              by computer nerds, slacker students, innovative capitalists, social activists, trendy academics, futurist
              bureaucrats and opportunistic politicians across the USA.
            </p>

            <br><br>

            In the transition from the Industrial into the Knowledge Age, cyberspace, the internet, and computers were
            seen as tools for emancipation from the established power and hierarchy. Colonizing this new immaterial
            space
            is an exciting opportunity for freedom and liberation. The Californian counterculture of the 1960s was
            reshaped, during the following decades, into a paradoxical ideology connecting two opposite but equally
            powerful aspirations: the collective adventure enabled by the new reach of global communications and a
            complete professional autonomy thriving on personal success. Marshall McLuhan’s global village theory and
            the
            libertarianism promoted by Ayn Rand’s allegories were hybridized in the start-up culture which, in the name
            of
            innovation, does not perceive, or refuse to admit, the discrepancies of its economic model.
            Between the 1980s and the end of the twentieth century, cyberspace is still a place where market regulations
            are inapplicable or unapplied. Therefore, we witnessed the surge of contrasting visions for the possible
            missions of the internet. The philosophy of the free exchange of knowledge—brought about by activists such
            as
            Aaron Swartz—which fosters openness and collaboration, sets aside the liberal ideal of the conquest of
            cyberspace as a new market, denying any empathy or collaborative spirit, and promoting one’s personal
            success
            at any price.
            The aftermath of this paradoxical conjunction was the advent of start-ups companies born as opponents of
            powerful economic giants that have metamorphosized into giant infrastructures. Apple Computer and Adobe
            Systems—companies hardly avoidable in the professional graphic design field—are striking examples. Both
            corporations initially thriving for innovation with the mission of offering technological autonomy to their
            customers, have progressively been transformed into market dominators, forbidding any emancipation from
            their
            products.


            <h3>1.1.1 Apple Computer</h3>
            Invited by the TV show The Computer Chronicles, “icon designer” Susan Kare and Product Design Manager Jerry
            Manock presented, in 1985, the newly released Apple computer. Ergonomically studied to be light, portable,
            and
            user-friendly, the Macintosh was designed to be used by the “99th percentile of males, females, and
            children,”
            Maddock stated. Developed to allow comprehensive accessibility, the interface system and icons were created
            to
            be clearly and quickly understood and assimilated. Susan Kare shared during the interview that “one of the
            best experiences,” was how to easily teach in roughly twenty minutes to use the Macintosh to those who have
            never used a computer before. This was made possible because the function of each icon does not need
            additional verbal explanation. Interface and object’s ergonomics translated into reality what Steve Jobs
            foresaw few years earlier: “bringing computers to the people, with the cheerful but affordable design of an
            Eichler home and the ease of use of a sleek kitchen appliance.”
            It is paramount to remember that, considering the historical and geographical context in which the Macintosh
            was conceived, its design was inherently western centered. With its focus positioned on the wealthy
            majority,
            Apple partially ignored any inclusive design principle devoted to minorities or “special people,”
            fundamentals
            outlined, a few years later, by Don Norman in his The Design of Everyday Things. Nevertheless,
            “accessibility”
            and “affordability” were at the center of Apple’s communication. The seeds of Apple’s worldwide triumph of
            the
            following decades were grounded in these few concepts, as well as its paradox.
            Describing the interface, Susan Kare highlighted the similarities between Macintosh icons and daily life
            objects: the interface mimicked the interactions with our surroundings. We could easily recognize a
            “document”
            that we organized in a “folder.” If we saw clock hands turning, we could understand that we had to wait for
            time to pass. We calculated simple operations with a pocket calculator, and we put it in the trash can
            documents that we wanted to throw away.

            Since the creation of the personal computer, this intuitive strategy for computer interaction was
            groundbreaking, emancipating users from the need for a deep understanding of inherent machine language. The
            space between the human being and the machine was now inhabited by an interface that functioned as a
            translator. Interface design, thus, became strategic.

            <br><br>
            <p class="quote">The concept [of the interface] lies across a critical boundary—between material and
              immaterial reality. […]
              interface is also the immaterial meeting place between two states of reality, previously extraneous, that
              merge to exchange information, to interact. […] Around the concept of the interface, the relationship
              between
              man and machine calls up the problem of access—man must have access to the machine, and the machine must
              have
              access to the men, in a process that aims at attaining specific objectives.
            </p>
            <br><br>
            The “specific objective” was evidently to facilitate the use of the machine, yet in a consumerist-driven
            effort to conquer a new market. Here resided the paradox: in the trajectory towards innovative
            accessibility,
            tech corporations have interposed an interface between the human and the machine which, while facilitating
            comprehension of the functions, undermined the user’s personal responsibility of understanding, and learning
            the machine’s language. The result was users’ lack of autonomy, with a consequent submission and dependence
            on
            technology. The accessibility, presented as a pedagogical gesture to emancipate users from the computer’s
            complexity, resulted instead in their disempowerment. The pedagogical preoccupation was thus solely to
            educate
            a bigger audience, with the objective of attracting customers.
            Observing the evolution of Apple’s interfaces from its early stages till the beginning of the 2000s, we
            recognize a development towards a skeuomorphic visual language that brought, in parallel, a progressive
            closure of the operating system. Although Apple’s first Macintosh, included a “program to make programs”
            such
            as HyperCard which allowed its users to actively engage with the computer, this interactivity has become
            increasingly less accessible in newer machines. With the release of macOS X, the customization of graphic
            software through the installation of plug-ins became almost a quest. The fast, powerful, and fancy Apple
            computers of the beginning of the new century almost completely lost their modularity and customizability.
            Despite mimicking a three-dimensional space, their interfaces induced, instead, a linear and flat use of the
            device, preventing any in-depth interaction.

            <h3>1.1.2 Adobe Systems</h3>
            Founded in 1982, Adobe (originally Adobe Systems) has been Apple’s entrepreneurial companion from its early
            stages. From creating the Postscript printing protocol, which allowed Apple to succeed in the desktop
            publishing industry, to developing the early versions of Illustrator for the Macintosh environment only,
            Adobe
            has been Apple’s wing person in its entrepreneurial journey.
            Adobe’s founders John Warnock and Charles Geschke shared the story and philosophy of the company during its
            twentieth-anniversary celebration in 2002. Grounded in the Silicon Valley ideology, Adobe echoes the
            entrepreneurial vision of the start-up culture. At a time, in the early 1980s, in which the desktop printing
            market—the first territory of their intervention—was not yet defined or understood, Adobe has always thrived
            on innovation, focusing their efforts on groundbreaking products, designed to anticipate trends and market’s
            demands. The advent of the PostScript protocol, Adobe’s first product and precursor of the open and standard
            PDF format, marked a new printing revolution. Bridging the screen and the paper—the “what-you-see” to the
            “what-you-get”—the PostScript language, implemented in the LaserWriter produced by Apple, profoundly
            reformed
            the graphic design industry, joining the immateriality of the screen to the materiality of the page and
            showing a concrete use of the computer to create graphics that could be converted in a quality tangible
            output.
            During the conference “Adobe Systems: The Founder’s Perspective,” Geschke addressed the two main points of
            Adobe’s philosophy of the time: “Everybody should have their own computer. […] A computer is not primarily
            used to calculate; it’s used to communicate.” Giving access to technology to a wider market remains, as for
            Apple, one of the initial preoccupations of the company. And giving them the opportunity to imagine a
            pragmatic use of the machine computer with the connection to a printer was a breakthrough. Nevertheless,
            from
            an entrepreneurial standpoint, diversifying their product was critical for the company’s survival.
            In 1986, Adobe released the first version of Adobe illustrator, betting on the new and unlikely graphic
            design
            field: apart from cutting-edge experimentations of the few, most of the graphic designers had not yet, at
            the
            time, appropriated and integrated the computer as a production device. Quickly, Adobe Photoshop joined its
            fellow Illustrator and, together, they started conquering designers’ fantasies. Selling the illusion of
            condensing, inside the computer box, and behind the screen, all graphical experimentations previously
            envisioned in the material realm, Adobe designated the computer as the new, compact, mono-tool for the
            visual
            arts.
            The expansion, during the 1990s, of graphic design programs undeniably empowered for a while the graphic
            design production pushing further the postmodernist experimentations like those initiated by designers such
            as
            the Swiss Wolfgang Weingart. The binomial computer/software allowed to de-structure, decompose, recompose,
            and
            reimagine elements (typography, grids, and layout) in newer, faster, easier, unexpected ways, contributing
            to
            establishing a different temporality for the projects and reforming the design process. The work of
            designers
            like David Carson, Neville Brody, or Rudy VanderLans, and Zuzana Licko exploited these new frontiers and
            pushed the boundaries of their research focused on hybrid forms on the edge between traditional and
            unconventional design: “We both [VanderLans and Licko], each in our own way, really enjoyed this machine. It
            forced us to question everything we had learnt about design. We both enjoyed that process of exploration, of
            how far you could push the limits.”
            At the beginning of the twenty-first century, the major success of their products led Adobe to progress
            exponentially. Expanding the offer and acquiring competitors’ products and companies, the corporation-to-be
            set a new trajectory for conquering the market—a market they helped define—and assembled an entire armada of
            design programs. These years marked a pivot, shifting Adobe from a dynamic start-up that injected new
            perspectives for the design practice to a colossal infrastructure dominating the graphic design production.
            The visual excitement of the 1990s faded away, replaced by the feeling of being trapped in a conventional
            and
            expensive “golden cage,” with no possibility of expression out of the standardized path drawn by Adobe’s
            programs and interfaces.
            <br><br>
            Over time, Adobe's interfaces have developed the same inherent structure, offering a global, consistent, and
            comforting environment for their users. Enabled to quickly recognize the graphic setting of the programs and
            easily appropriate the new functionalities, users felt in control of the workflow. However, the comfort of a
            recognizable interface generated a standardization of the esthetics of graphic design productions and a
            conformity in the methodological patters of creation. Employing the same tools, with the same interfaces,
            engendered the harmonization of the mechanical gestures and behaviors during the design process.
            Furthermore,
            the acceleration of the temporality of production, caused by a hyper-consumerist market, encouraged the
            designers to take advantage of the comfort of Adobe’s environment, and prevented any further design
            exploration of forms or tools.
            The conformity of design esthetics engendered by the standardization of the design tools is critical.
            However,
            to better frame the implication of Adobe becoming a monopoly, the question of affordability, and thus of
            accessibility, is crucial. Since the release of the first programs, the cost of the products has been
            prohibitive for most visual artists and designers, rejecting the economic minorities from the profession.
            Being a graphic designer was (and still is) a privilege, as it implies having the capacity of buying a
            computer (Apple) and the programs (Adobe for the most part) needed to create artwork. An underground market
            of
            cracked software provided, for years, the solution for some designers to start their activity until, in
            2013,
            Adobe moved to a subscription-only model, removing any standalone versions. The customers are not the owners
            of the programs they use, and they pay a monthly subscription to access them. If the subscription model can
            be
            legitimate for commodities such as video on demand, the model becomes questionable when applied to
            professional tools required for working.
            In October 2019, Adobe temporarily blocked the access to Venezuelan customers to their products and enabled
            their customers to access their work on the Creative Cloud. The decision came in conformity with the US
            government’s decision of prohibiting transactions and services between companies of the United States and
            Venezuela and dramatically revealed the flaw of their subscription-only business model. After month of
            negotiations with the US government, Adobe was able to restore the Venezuelan customers’ access to the
            Cloud.
            Nevertheless, the incident revealed the fragility of designers’ freedom and independence from the Adobe’s
            monopoly, and shown some inconsistencies between the philosophy of the company and its actions:

            <p class="quote">The other philosophy that we have internally […] in the way that our company should operate
              [is based on] one rule: if you are confused [about] how to deal with a fellow employee, a customer, a
              shareholder, or someone out there in the community that you are interfacing with, just treat the
              individual
              the way you’d like to be treated. […] That would be the Adobe way. Because when you are in business, your
              customers, in many cases, have their business critically dependent on your ability to deliver a quality
              product on time when you promise it.
            </p>

            <h3>1.1.3 Google Design</h3>
            We have observed how Apple and Adobe contributed to creating and developing the computer and software market
            in the graphic design field. Providing tools which simplified the intellectual access to the computers, they
            have educated, during the years, designers as well as a broader audience, and enabled them to appropriate
            the
            computer—till that moment seen as a computational machine for calculations—as a tool for communication and
            visual creation. Both Apple and Adobe’s efforts towards accessibility translated into creating environments
            and interfaces that were easy to use and understand. However, the temporary users’ understanding of the
            personal computer’s functions has metamorphosized into a lack of autonomy in front of the ever-changing
            technology. From the middle of the 1980s to the beginning of the 2000s, we witnessed the increase of the
            separation between the user and the computer, which concretized in the standardization of the design
            methodologies caused by the extended offer of programs relying on same interactive patterns.
            Google can be identified as the third actor that heavily contributed to the normalization of graphic design
            esthetics and methodologies. With the release of Google Fonts (originally Google Web Fonts), Google began a
            new business model for tech companies proposing free graphic design components distributed on the internet.
            This gesture towards a sharing strategy that echoes the open source model has democratized the access to
            design yet fostered the commodification of the design culture through the standardization of its esthetics.
            This event was critical in redefining the concept of accessibility. Google Font provided young designers and
            design students an affordable alternative to access, explore, and use typography; yet, it started colonizing
            the graphic design field, with professionals and agencies taking advantage of the easy-to-use and free
            offer,
            forgoing the singularity and uniqueness that typographers used to bring to each design project. In January
            2019, the branding agency Carré Noir redesigned the city of Paris’ logo and identity, using the font
            Montserrat as its main typeface—one of Google Font’s best sellers.
            Is this business model a simple gesture to emancipate the users? The paradox of innovation of the start-up
            culture is still current. The shift toward a more open business model seems to benefit the tech corporation
            that, in providing commodities, retains its customers in its comforting cybercommunity. The complexity of
            defining “accessibility” is critical. Does Google’s “accessibility” mean providing access to products or
            providing tools for autonomy? Is accessibility equal to emancipation, or just another way to conquer the
            market?
            In 2015, Google released Material Design, a comprehensive catalog of design components to create interactive
            applications, and published the documentation and specs online as an open platform. Material Design was
            thought to give consistency to the interactive interfaces of Android products (Apple’s competitor). Giving
            open access to design tools with the mission of providing accessibility to a better design seemed innovative
            and far-sighted. If we watch the teaser Making Material Design published online for the release, we can
            identify some keywords such as “collaboration,” “community,” “experiment” that are repositioning the
            philosophy of Google towards a place close to the free open source approach.
            The proposition is appealing. Nevertheless, the main consequences of Google’s proposition are the esthetical
            uniformity of interaction design products’, and the weakening of designers’ legitimacy as professional
            experts. Presenting the color palettes of Material Design, Google’s Senior Designer Rachel Been stated:
            “[with] this really simplified and easy-to-use system, […] someone who never took a color theory class could
            create a combination of colors within their products that felt harmonious.”
            Google has drastically contributed to the commodification of design practice and culture, fostering an ideal
            of “universal design” open to everyone, for everyone, by everyone, dramatically undermining the importance
            of
            designing with a focus on singularities. Matias Duarte, Vice-President of Material Design, reiterated their
            ideal of proposing principles of design that “should be timeless” in order to achieve a universal framework.
            The concepts of universality and accessibility are, thus, central to this thesis’ investigations.
            For years, the free open source culture’s communities have pursued a parallel path, observing the
            development
            of the tech giants and, sometimes, raising their voice to expose the injustices created by the new
            hierarchies
            they have put into place. Processing’s community has contributed the most to a critical approach to design
            aimed to empower the user instead of having them be submitted to a passive stance. Before diving into
            Processing’s story, the next section will retrace the path of the free open source culture and communities
            situating them historically and geographically.

            <h2>1.2 From Hackers to FLOSS (Free/Libre Open Source Software): A Moral Debate</h2>

            For years in the shadow, often misunderstood and stigmatized, the legacy inherited from programmers and
            software developers has tremendously influenced the approach fostered by the Processing community. Between
            the
            1960s and the 2000s, hacking, free software, and open source grew in parallel with the start-up culture,
            countering the capitalistic and consumer-driven orientation that was colonizing the field of software
            development at the time. Despite the fact that hackers and open source methodologies are now actively
            inspiring the contemporary design fields, the terminology referring to those cultures is often misused or,
            worse, misunderstood.
            To better frame the meaning of “free open source culture” employed in this research, this section analyzes
            some of the central texts that modeled the cultures of hackers, free software, and open source, and
            clarifies
            their terminology. Through the following literature review, this research retraces the path connecting the
            hackers’ ethics rooted in the MIT of the 1950s, through the open source methodology established in the late
            1990s, till the contemporary definition of FLOSS (Free/Libre Open Source Software), and continues further to
            reveal the sour debate about the ethics of software development and distribution, that emerged at the end of
            the last century.

            <h3>1.2.1 Hackers: A Matter of Jargon</h3>
            Allison Parrish, programmer, artist, and educator introduced her opening keynote at the Open Hardware Summit
            2016 as following: “Every practice, whether technical or artistic, has a history and a culture, and you
            can’t
            understand the tools without understanding the culture and vice-versa. Computer programming is no different.
            […] Part of the challenge of teaching computer programming is making the history and culture available to my
            students so they can better understand the tools I’m teaching them to use.” History and culture are
            inherently
            related to language and vocabulary. Parrish exemplifies this in her keynote, describing how, as a teenager,
            young programmer, and computer passionate, she relied on the software developer Eric S. Raymond’s “Jargon
            File” to feel like she belonged to “the glory days of hacking and the computer revolution.” Born in 1981,
            she
            was too young to have lived the era, between the 1950s and the 1980s, during which hackers’ terminology and
            their values were rooted. She thus consciously adopted the “Jargon File” as her own culture.”
            First published in the early 1990s, the informal web text the “Jargon File” is still considered one of the
            primary references to define hacker’s terminology. Raymond is one of the most influential and prolific
            theorists who thoroughly contributed to defining, promoting, and supporting the hacker’s community and the
            open source development model. In 1996, he published How to Become a Hacker: “As editor of the ‘Jargon File’
            and author of a few other well-known documents of similar nature, I often get email requests from
            enthusiastic
            network newbies asking (in effect) ‘how can I learn to be a wizardly hacker?’ Oddly enough there don’t seem
            to
            be any other FAQs or web documents that address this vital question, so here’s mine.”
            What is a hacker, then? First, to demystify the communal belief about hackers, it is essential to make a
            clear
            distinction between the concept of “hackers” and the one of “crackers.” The media have often wrongly
            depicted
            hackers as people employing their skills to steal credit card numbers or sell confidential information. But
            if
            we refer to hackers’ literature on the internet, we understand that this behavior is considered, by the
            hacker
            community itself, as “lazy, irresponsible, and not very bright.” In How to Become a Hacker, Eric Raymond
            stated that “being able to break security doesn’t make you a hacker any more than being able to hotwire cars
            makes you an automotive engineer. […] The basic difference is this: hackers build things, crackers break
            them.”
            A few years earlier, in 1984, writer and journalist Steven Levy published Hackers. Heroes of the Computer
            Revolution. Levy portraited the “the glory days of hacking and the computer revolution” dreamed by Allison
            Parrish and retraced the origins of the term “hacker” and narrated the community’s early pranks in the rooms
            of MIT. In the preface to the 2010 edition, Levy stated:

            <p class="quote">I was first drawn to writing about hackers—those computer programmers and designers who
              regard computing as the most important thing in the world—because they were such fascinating people.
              Though
              some in the field used the term “hacker” as a form of derision, implying that hackers were either nerdy
              social outcasts or “unprofessional” programmers who wrote dirty, “nonstandard” computer code, I found them
              quite different. Beneath their often unimposing exteriors, they were adventurers, visionaries,
              risk-takers,
              artists… and the ones who most clearly saw why the computer was a truly revolutionary tool. […] I came to
              understand why true hackers consider the term an appellation of honor rather than a pejorative.
            </p>

            To restore that vision of the community, Levy listed the Hacker Ethic, a series of principles that are still
            claimed, by the contemporary programming community, as their foundation: unlimited access to computers,
            freedom of information, decentralization of power, and anti-academic position. Levy concluded the list with:
            “You can create art and beauty on a computer” and “Computers can change your life for the better.” Although
            certain aspects remain controversial, Levy’s Hacker Ethic still reflected the building blocks not only of
            the
            hacker culture, but of the communities that have been inspired by the free software and open source models.

            <h3>1.2.2 Open Source and Free Software: A Fracture</h3>
            Hackers’ approach, based on decentralization, collaboration, and free access to computers, programs, and
            information, continue to inspire parts of the contemporary design scene. Nevertheless, probably to distance
            themselves from a community too quickly stigmatized, the contemporary promoters of these principles prefer
            to
            define themselves as part of the open source movement.
            Over the last fifteen years, the term “open source” has increasingly gained notability, and its use has been
            “stretched [to] activities, such as government, education, and science, where there is no such thing as
            source
            code.” The open source methodology is built on decentralization and collaboration; yet “open source” does
            not
            imply freedom of access, use, replication, and distribution.
            The arise of the term “open source” is inherently connected to Linus Torvalds’s lifetime work, the open
            source
            operating system Linux, still considered one of the “world’s largest collaborative projects.” His work was
            an
            essential contribution in exposing the open source model—and in consequentially defining it—but also caused
            the fracture between the free software and the open source movements, in opposition about the ethics of
            software distribution. The story of Linux is summarized in Torvalds’s auto-biographical book Just for Fun.
            The
            Story of an Accidental Revolutionary. The book title alludes to Torvalds’s position regarding his work and
            the
            reasons for its success. Educated in Finland, a culture where “greediness was perceived as suspicious,” and
            raised by a “diehard communist father,” Torvalds never thought of his work as commercially valuable. The
            intellectual aspect of it and the excitement of proposing a working piece of software were his driving
            forces.
            Sharing his code with others to collectively develop and solve problems simply seemed practical to him. His
            intention was not to create a worldwide example of collaborative work or to build his career. He made it
            Just
            for Fun, the result of an intellectual, not strictly commercial, vocation.
            Inspired by Linus Torvalds’s work, Eric Raymond wrote in the late 1990s, The Cathedral & the Bazaar,
            published
            in 2001. Central in defining the open-source methodology, Raymond’s essay theorized about the bazaar’s
            bottom-up methodology based on decentralization and collaboration and juxtaposed it to the cathedral’s
            top-down design, typical of traditional development models. With the foundation in 1998 of the Open Source
            Initiative (OSI) , Raymond distanced himself from the radical position of the Free Software Foundation,
            founded in 1986 and led by Richard Stallman:


            <p class="quote">If [Stallman’s] rhetoric had been effective outside the hacker community, we’d have gotten
              where we are now five or ten years sooner, and OSI would have been completely unnecessary (and I could be
              writing code, which I’d much rather be doing than this...). […] So, when RMS insists that we talk about
              ‘computer users’ rights,’ he’s issuing a dangerously attractive invitation to us to repeat old failures.
              It’s one we should reject -- not because his principles are wrong, but because that kind of language,
              applied to software, simply does not persuade anybody but us. In fact, it confuses and repels most people
              outside our culture.
            </p>

            Stallman clearly stated his disagreement with the Open Source Initiative in his critical text “Why Open
            Source
            Misses the Point of Free Software”:

            <p class="quote">The terms ‘free software’ and ‘open source’ stand for almost the same range of programs.
              However, they say deeply different things about those programs, based on different values. The free
              software
              movement campaigns for freedom for the users of computing; it is a movement for freedom and justice. By
              contrast, the open source idea values mainly practical advantage and does not campaign for principles.
              This
              is why we do not agree with open source and do not use that term.
            </p>

            If the debate is legitimate, paradoxically, Torvalds’s decentralized model did not have any ethical
            implications, per se. In his book Just for Fun, Torvalds distance himself from the moral debate between open
            source and free software, rejecting any label that Stallman or Raymond would put on him. He admits admiring
            and respecting both opponents but does not want to engage in the controversy.
            The fracture between the open-source and free software ideologies (or rhetoric) is still a contemporary and
            relevant debate. Language often defines cultures and claiming to stand for the open source, or the free
            software model could have profound moral, ethical, and political implications.

            <h3>1.2.3 FLOS Software and FLOS Culture for the Visual Arts</h3>
            The controversy that emerged twenty years ago around software accessibility is still relevant and has
            infiltrated fields not explicitly connected to software development. The acronym FLOSS that stands for
            Free/Libre Open Source Software has been coined to partially “bridge the [free software and open source]
            communities and their differing opinions.” Casey Reas, co-creator of the Processing environment, published
            in
            2017 the article “Processing and FLOSS,” which revamped the debate, extending it to the visual arts. It also
            served to clarify the Processing community’s moral position on this matter. He adopted a position of
            neutrality in front of the radical opposition of free software and open source, while underlining the
            Processing community’s commitment for accessibility and free (libre) exchange: “Many people in the Free
            Software community argue with people who promote Open-Source software about fundamental ideas and vice
            versa.
            […] The acronym FLOSS is sometimes used to bridge the communities and their differing opinions. The word
            libre
            is added to free to make the goal of ‘free as in freedom,’ the ideals of liberty, more clear.”
            Reas refers to Stallman’s article “Why Open Source Misses the Point of Free Software,” and clarifies his
            position about software for the visual arts, reiterating the importance of the tools’ authorship, which
            allows
            to shape our work as we intend, without relying to corporations and ready-made platforms. He concludes: “We
            believe in the fundamental freedoms of Free Software and that is our path.”
            As this research will investigate in the following chapters, moral commitment is crucial for the community
            which has developed around the Processing environment. The idea of a community fostering the principles of
            freedom and accessibility is an aspiration Reas reiterates in his “Thoughts on Software for the Visual
            Arts”:
            “I have seen independent creators build local and networked communities to share intellectual resources and
            tools. […] It’s an aspiration toward a way of making and sharing that has been strongest in one area of the
            visual arts, the world of creator-programmers. I want to try to scale it within that context and I also want
            to know if it’s applicable to other areas.”
            Based on Reas’s postulate, we can legitimately use “free open source” to describe not only software
            programming but also cultures and communities built on the idea of decentralization, collaboration, and free
            access to information. If “free” is intended as “freedom” and “source” as “documentation,” it is possible to
            make the transition from “free open source software” to “free open source culture.”

            <h2>1.3 Conclusion: Joining the Dots</h2>
            Since the end of the twentieth century, Silicon Valley and its economic success have driven the imagination
            of
            young companies worldwide and have established new objectives for innovation in the economy of knowledge.
            The
            excitement of the new economic frontiers brought about by new technologies has shaped generations of young
            entrepreneurs, inspired by tech corporations’ pioneers like Steve Jobs: “We are inventing the future. Think
            about surfing on the front edge of a wave. It’s really exhilarating. […] Come down here and make a dent in
            the
            universe.” Nevertheless, this optimistic vision has been recognized as a false promise. The hope of
            emancipation from the social and economic establishment brought about by computers and the internet has
            resulted in a re-centralization of the economic power in the tech giants’ hands. Technology is unavoidable
            and
            especially the technological infrastructures that have colonized cyberspace.
            Design practices have particularly suffered from this new paradigm: the professional graphic design market
            employing the tools offered by companies such as Apple and Adobe, struggled to find viable alternatives to
            their products. The monopolization of the tools for graphic design, in a pretended effort for universal
            accessibility—alas too often focused on the wealthy majority—have instead fostered progressive
            inaccessibility
            of the core of the technology itself, removing the necessity of learning the machine’s language, and
            trapping
            its users in a “golden cage.” This paradoxical situation has created a standardization of the production
            (the
            same tools produce the same esthetics) and, as Casey Reas highlighted in the CAST Symposium of 2017 “Being
            Material,” it has generated the crisis of creative methodologies.
            Nevertheless, alternative production models emerged in the legacy of hackers and open source cultures. As
            the
            report or the Progress and Freedom Foundation foresaw in 1994, “It is clear […] that cyberspace will play an
            important role knitting together in the diverse communities of tomorrow, facilitating the creation of
            ‘electronic neighborhoods’ bound together not by geography but by shared interests.” These communities
            brought
            together by the virtual space of the internet provided a new vision in the quest for alternatives to the
            centralized power, detached by consumerist ambitions and converging towards a radical exploration of new
            forms
            of production and distribution. The free and open source dynamics have inspired new designers and initiated
            their emancipation, concretized in the self-production of tools and in a revamping of social and political
            engagements.
            If we identify the Silicon Valley as the cradle of the start-up culture, the free open source culture’s
            would
            be MIT, where the roots of hackers and DIY cultures can be found. Towards the end of the twentieth century,
            compelling explorations emerged within this space for research, in the form of an in-depth investigation of
            the potentiality of new computational machines. MIT’s open and exploratory approach catalyzed designers,
            artists, and researchers who were looking for new, radical dynamics.
            It was in this context of experimental research and embracing the principles of the free open source culture
            rooted in cyberspace, that Processing set its moral position. “The web extended values from decades prior,”
            Reas stated, “it accelerated the promise of more universal access to information, of creating new kinds of
            communities, and of breaking down hierarchies. These values are shared with the origins of Processing.”
            Following the path of Muriel Cooper and John Maeda, and through the discovery of Casey Reas and Ben Fry’s
            work, the next chapter will reveal Processing’s origins and describes its evolution from a programming
            language to a community fostering diversity and inclusion.
          </div>
        </section>
      </div>

      <section>
        <div class="oneCol">
          <h1>2. Processing: from Code to Platform</h1>
        </div>

        <div class="twoCol">
          <p class="quote">It’s hard to pin down what Processing is, precisely. I admit, it can be confusing, but here
            it is: it’s
            both
            a programming environment and a programming language, but it’s also an approach to building a software
            tool
            that incorporates its community into the definition. It’s more accurate to call Processing a platform—a
            platform for experimentation, thinking, and learning. It’s a foundation and beginning more than a
            conclusion.
            — Casey Reas, “Thoughts on Software for the Visual Arts”, 2019.
          </p>

          Processing is complex to define, and the risk of reducing it to a coding language would undermine its
          scope.
          The project’s complexity represents its richness and translates the multiplicity of influences and
          intents.
          In the first chapter, we exemplified how the triad “computer-software-internet” has been ruled by tech
          giants such as Apple, Adobe, and Google, and how these monopolies have chained graphic design
          professionals
          into closed workspaces, generating a standardization of the esthetics and a crisis in design
          methodologies.
          Processing’s proposition of “language-environment-community” seems to provide alternatives to these
          dynamics
          and to reverse the paradigm of creation in the visual arts, allowing the designer to become the actor of a
          tool’s production and a work’s distribution.
          This chapter investigates the path that led to the birth of Processing and clarifies how its coding
          language
          and programming environment has evolved into a “platform,” inspiring new generations of artists and
          designers and empowering their practice. We first unveil the dialogue between Processing and its
          predecessors to show evidence of the tight connection with MIT and the graphic design practice. Through
          the
          analysis of the platform’s main components—language, environment, community—this chapter examines how
          Processing has expanded the concept of accessibility, questioning its economic, social, and political
          aspects, and has fostered values of inclusion as a critical part of the project.

          <h2>2.1 MIT’s Heritage</h2>
          <p class="quote">Processing […] was born at the MIT Media Lab, a place where C. P. Snow’s two cultures (the
            humanities and the
            sciences) could synthesize. […] Processing wasn’t pulled from the air; it was deeply rooted in decades of
            prior work.
            — Casey Reas, “Thoughts on Software for the Visual Arts,” 2019.
          </p>

          Processing’s complexity and relevance result from the combination of several influences, most of which are
          rooted at MIT. The connection between Processing and the free open source culture, also partially originated
          at MIT, was exemplified in the previous chapter: hackers, open source, and FLOSS approaches jointly informed
          Processing’s sharing model and initiated a new investigation about “accessibility.” Nevertheless, the thread
          connecting Processing to MIT consolidated between the mid-1970s and the late 1990s, when the MIT Media Lab, a
          space of groundbreaking experimental research, became the cradle of humanities and science’s conjunction.
          Muriel Cooper’s Visual Language Workshop (VLW), followed by John Maeda’s Aesthetics and Computation Group
          (ACG), both part of the Media Lab, are undoubtedly the two laboratories that provided the building blocks of
          Processing’s platform. Both Cooper’s interdisciplinary experimentation, informed by her graphic design
          background, and Maeda’s approach to code as a creative tool bloomed in 2001 in Processing.

          <h3>2.1.1 Muriel Cooper: from Visual Language Workshop to Information Landscapes</h3>
          In 1994, a few months before suddenly passing away, Muriel Cooper, graphic designer and researcher, presented,
          at TED5 Conference, her project Information Landscapes, the result of the Visual Language Workshop’s research
          of the prior decade. The Visual Language Workshop (VLW) was founded by Cooper in 1974. After having worked for
          over twenty years as a designer and art director at MIT Press, Cooper moved towards education and created a
          hybrid space, in which teaching and research intersected: the transdisciplinary approach inspired by the
          Bauhaus and the rigorous graphic investigations of the Swiss Style equally permeated her projects’
          development. With the assistance of her students, Cooper cross-referenced media, materials, and processes,
          echoing the explorations of European postmodernist graphic designers of the same period, such as Weingart or
          Gerstner. Operating within MIT, the cradle of computer science, gave Cooper the opportunity to rapidly access
          powerful computers. She embraced these as an additional experimentation tool: Information Landscapes
          represents one of the most remarkable results and a groundbreaking moment of her career.
          Adding graphic design preoccupations, such as legibility and typographic arrangement, to data selection and
          fruition—a field equally explored within MIT through the research project DataLand —Cooper focused on the
          three-dimensionality and depth of the inherent architecture of the computer. She foresaw this space as a means
          to develop interfaces that embraced the simultaneity and superposition of information and expanded the
          potentiality of human perception. Cooper’s purpose was to redefine graphic design, integrating McLuhan’s
          theories of simultaneous relationships “where a visual space is an organized continuum of a uniform connected
          kind.” With her investigation, Cooper showed alternatives to Adobe and Apple’s linearity and flatness: the
          black background opposed the white page simulated by the WYSIWYG interfaces (see fig. 1.7); Cooper’s zoom-in
          brought you “inside” the interface itself and not “closer” to the page’s surface (see fig. 1.5); the
          interaction with the information was flexible and multiplied the observer’s possible points of view,
          countering the constraint and rigidity of Apple’s desktop space. This thesis postulates that this flexibility
          has opened interesting paths for design research based on “multiversality” as opposed to mainstream design
          research focusing on “universality.” This flexibility reflects the ideals of inclusion and openness which were
          developed throughout the Processing community years later, as this thesis exemplifies in later sections.
          Muriel Cooper’s work informed Processing and inspired its creators on several levels. Ben Fry’s work—as part
          of the contemporary Information Design and Data Visualization scene—reflected formally and conceptually
          Cooper’s effort of connecting to the inner architecture of the computer to translate data into compelling and
          relevant visuals, allowing access to complex information.
          Additionally, Cooper’s methodological approach, resonating with the Bauhaus’, has greatly influenced the
          pedagogical perspective that shaped Processing creation: “the idea of traditional foundational studies was
          really important to Processing. I thought it was another Bauhaus moment. I thought, in the same way that
          during the Bauhaus era we moved from arts-and-crafts production into industrialized production, it was time to
          move from industrial production into the computer software, information-based production.”
          Another element completing the creation of the multifaceted Processing came from computational design.
          Cooper’s practice, impregnated by experimentation and trans-disciplinarity, opened the path for implementing
          computation as a means for visual expression.

          <h3>2.1.2 John Maeda: from Aesthetics + Computation Group to Design by Numbers</h3>
          The Aesthetics + Computation Group (ACG) was founded by John Maeda in 1996 to continue the work put in place
          by Muriel Cooper. Back to the United States following his graphic design studies in Japan, John Maeda wanted
          to further explore the intersection of art, design, and technology. The particularity of Maeda’s lab proposal
          was the use of programming as a creative tool to explore new forms in graphic design. At the time, programming
          was a territory almost exclusively related to computer science and mathematics. Despite the pioneer
          exploration initiated in the 1970s by a fringe of artists, the idea of programming as a visual tool had not
          yet been implemented in any research institution or program. Attracted by this unconventional approach, Reas
          and Fry decided to join the program and, working under the supervision of Maeda, they planted the seeds of
          Processing. “I don’t think Processing would exist without John Maeda. The story starts there. Ben and I both
          came to MIT to study with John specifically because he was bridging ideas of computer science and design
          together,” said Reas.
          To teach programming to designers and visual artists with no coding skills, Maeda developed a simple,
          accessible, and easy-to-use digital tool, Design by Numbers (DBN), implementing elementary commands to create
          dynamic images in a black and white 100x100 pixel screen canvas. Through its simplicity, DBN had already
          integrated the concept of accessibility that Processing would come to develop years later. The concise and
          friendly interface was equipped with few buttons, and the concept “code, push play, and see” foresaw how
          visual people could seize and appropriate programming, quickly visualize the result of their work, and avoid
          the tedious labor with text and math.
          Maeda pushed his undertaking even further: alongside his mission to educate designers to use code as a tool
          for visual expression, he unveiled the inner structure of software thus inviting the students to appropriate
          digital tools. “My intent is to help build a basic understanding of the process behind creating a computer
          program. […] You probably won’t be able to program the next competitor to Adobe’s last arsenal, but you will
          at least be able to appreciate the hidden alphanumeric chaos that underlies the digital design tools that many
          designers take for granted.” His work, imbued with the preoccupation of countering Adobe’s “arsenal,” sought
          to equip new generations of designers with the necessary understanding of software development, so as to shape
          their critical eye regarding the digital tools that were colonizing the graphic design field.

          <h3>2.1.3 Casey Reas and Ben Fry: Processing</h3>
          While David Carson and Neville Brody were experimenting with Photoshop and Illustrator and exploring their
          creative potential, Casey Reas and Ben Fry were already questioning the methodological limitations inherent to
          these tools. Visual artists with different practices, both interested in challenging their work through the
          intersection of art and science, Reas and Fry were aware of the constraints of the ready-made digital tools
          that appeared and arose at the end of the twentieth century. According to Fry, “tools like Photoshop and
          Illustrator […] allow you to build things, but really they separate you from the medium in a way that’s not
          always helpful. More importantly, you’re restricted by what the companies building those tools are making
          available to you. That’s a significant problem in terms of your creative output being controlled by a company
          whose priorities might not be aligned with yours and your best, most interesting, and most challenging work.”
          The creative process, framed by the functions that software companies made available to designers, was tied
          and submitted to tools’ limitations.
          Reas’s additional preoccupation was to change the way software was being integrated into art and design
          education: “I thought that the way schools were teaching students how to use Photoshop and Illustrator was
          entirely surface and didn’t even begin to explore the possibilities of new media. I wanted there to be a
          deeper understanding of the medium, rather than just using it as a tool.”
          Finally, a third concern permeated Reas and Fry’s research: the question of accessibility. If the interface
          proposed by Adobe and Apple allowed the users to quickly grasp computer and software’s functions, their cost
          was prohibitive for most artists and designers. On the other hand, the code available as an open source
          resource, thus completely free, represented a complex tool to apprehend without a formal training in computer
          science and programming. As teaching assistants at ACG, Reas and Fry had the opportunity to run workshops
          introducing Design by Numbers to designers. That was a breakthrough moment for recognizing the importance of a
          user-friendly interface to communicate a coding tool: “Those workshops really opened my eyes. We could sit
          with a group of people who had never coded before—people who were designers—and within an hour, they were
          making stuff.” This sentence echoes Susan Kare’s claim about the time needed to learn how to use a Macintosh.
          Learning from that experience, Reas and Fry decided to bring DBN to another level and expand the potential of
          the tool: “Processing tried to take the minimal aspects of DBN but also allow it to extend to the point where
          it was no longer purely a learning environment, but actually a full design and studio environment.”

          <h2>2.2 Processing: Language, Environment, Community</h2>
          As a synthesis of Cooper’s design approach, Maeda’s use of computational design, and the open source sharing
          model, the first version of Processing, was released in 2001. Processing’s purpose was to create an intuitive
          system like Maeda’s Design by Numbers, but expandable as a toolkit: adding color, changing size of the canvas,
          but also evolving with additional libraries the tool allowed to envision more complex and ambitious creative
          outcomes. Moreover, the program was available online as a free software, easy to download and, once installed,
          it was functioning as a self-contained programming environment. Any user, even a beginner, did not need extra
          features (not even an internet connection) to start “sketching” with code.
          The idea of “sketching” is central to understand the project’s essence. Unlike traditional coding
          methodologies, Processing wanted to focus on process more than on outcome. The user could visualize their
          code-generated images almost instantaneously, instead of having to write a complete program before seeing the
          results; this meant giving room for unexpected results to emerge, and ultimately embracing mistakes and
          failure as an active part of the learning. These components made Processing the perfect pedagogical tool for
          foundational Art and Design studies and a powerful device for creative professionals.
          The interface of Processing 1.0 was similar to the one developed for DBN (and never fundamentally evolved); it
          was composed of two windows: one in which to write code and one, activated by the “play” button, in which to
          “run” (visualize) the sketch. References and examples were available on the Processing website, which was used
          as an open documentation platform to support users in navigating the environment. Finally, Processing, like
          the operating system Linux years earlier, took advantage of a community of developers, creatives, and
          aficionados to expand and grow.
          In 2018, with the publication of “A Modern Prometheus” Casey Reas and Ben Fry summarized almost two decades of
          Processing history and reframed it as having been built on three main interlaced components: language,
          environment, community. In the following sections, we will unveil how these components embeds different and
          interwoven moral values, and propose a different way to apprehend the triad internet, computer, and software.

          <h3>2.2.1 Language: Code, Emergence and Multiverse</h3>
          <p class="quote">A lot of people would say that having to write the code to produce the page and images is
            actually a huge step
            backward from having a tool to do it. But one of the ways John [Maeda] put it that always struck me was this
            idea that you wouldn’t have a painter who doesn’t know how to mix paint themselves or work within their
            medium.
            — Ben Fry, “Processing: The Software That Shaped Creative Coding”, 2021.
          </p>
          Code is a system of symbols and rules used to communicate instructions to a computer. It can be considered the
          raw material, the alphabet, of programming language. Software is a digital medium that, programmed with code
          in a specific language, allows—in the case of creative software—to express and visualize ideas. When we use
          ready-made software like Adobe’s, we use functionalities that have been chosen and compiled by Adobe’s
          software developers to allow users to execute specific tasks. For instance, using Photoshop, we can change the
          contrast of a picture by sliding a cursor or modifying a curve on a graph. This action is possible because
          someone who “speaks the code” (the software developer) has provided an interface that eases the communication
          between users and machines: we can give instructions to a computer without typing them in its inherent
          language.
          Designers have been living with the illusion (and students have been educated with the conviction) that
          ready-made software, because of its interface, was the quickest and easiest means to digitally draw and
          visualize ideas. Nevertheless, taking the example of motion graphics programs like Adobe After Effects, the
          interface is so complex that a deep understanding of the software becomes highly laborious and time-consuming.
          The interface does not automatically shorten the digital visual work’s creation learning curve. Moreover, the
          pre-chosen features may prevent discovering unexpected outcomes. Despite slick interfaces’ support, graphic
          design productions are, as a result, often standardized because of a superficial knowledge of the complexity
          of the programs and, consequently, of a limited use of the multiple features of ready-made software.
          Casey Reas, in his interview “How to Draw with Code,” related his method of laying out ideas and sketching:
          his process included pencil and paper, but also a text editor in which, instead of writing notes for essays,
          poetry, or fiction, he organized logic and procedures. He wrote code to sketch; he sketched code. Within
          Reas’s research about “emergence,” culminated in his Process Series, a few lines of code and simple rules
          sufficed to visualize unexpected and compelling results that evolved following different combinations and
          variables. The rigid frame of ready-made software would not allow the flexibility and malleability that
          programming provides and, furthermore, would prevent the discovery of serendipitous accidents.
          Comparing his software to a music score, Reas explained that every time the program ran, it was performed
          differently, and new elements emerged and unfolded. “I think this is a very exciting way to work with
          computers because, stereotypically, they are such calculating precise machines, but being able to allow
          unexpected things to happen.” Embracing the infinite possibilities of each software’s performance echoes with
          Molnár’s expansion of the creative spectrum with the use of randomness. Both processes, allowed by the
          flexibility of the code and the potential of algorithmic procedural design, incapsulating the acceptance of
          different, divergent, and eventually contradictory results. Accepting every instance as part of the whole
          makes their approach naturally inclined to include diversity.
          As Muriel Cooper already suggested with Information Landscape’s design, this trajectory opposes the
          “universal” design supported by contemporary mainstream design trends. Instead of creating rigid frameworks,
          containing a limited number of possibilities (and structurally excluding some), a flexible design, centered on
          the idea of “multiverse,” would create, this thesis postulates, spaces for inclusion, and would open the path
          for a new design paradigm.

          <h3>2.2.2 Environment: An Expanded Field</h3>
          <p class="quote">P5.js is a reinterpretation of Processing. It takes the initial goals of Processing and asks,
            “What does that
            mean for today?” […] Instead of trying to retrofit those ideas into a project, we wondered: Can we try to
            build values of diversity and inclusion into the code from the get-go? We were making decisions in every
            moment, asking who are we privileging here? Who are we excluding? Who are we including? How do we make our
            message more explicit?

            — Lauren McCarthy, “How Computer Code Became a Modern Design Medium”, 2018.
          </p>

          In addition to the flexibility of the coding language, The Processing Development Environment (PDE)—the
          original software environment allowing beginners to start writing sketches—contributed to building a platform
          fostering values of inclusion. With the PDE, Processing’s creators aspired “to make the interface easy to use
          and the documentation clear and free of unnecessary technical jargon.” Proposing code-based software with a
          clear and comprehensible interface was a novelty in the free software development culture. Free and open
          source software, rooted in the text-based Unix programming philosophy, had very poor User Interfaces (UI).
          Culturally, free software developers were programming for themselves and other “experts” of the community, who
          did not need efficient UIs to navigate the software. The PDE was the first step to shift the paradigm of the
          free open source culture; it opened programming to communities, as the one of designers, that culturally did
          not “belong.”
          A huge step forward in shifting Processing toward a more inclusive environment was accomplished with Lauren
          McCarthy’s contribution: the JavaScript web library p5.js. Aware of the lack of diversity in programming
          communities, McCarthy joined Processing’s leading team in 2013 to expand the environment to become more
          inclusive. “One of the things we thought about really early on with p5 was the culture on GitHub, which is
          like the main place where the code base is developed. A lot of the conversations can be very aggressive, and
          you have to put yourself forward as an expert in order to be listened to. And we just really wanted to change
          that dynamic.” With the p5.js JavaScript library, Processing was transferred from the local PDE to the web,
          opening access to programming to an expanded community of non-expert eager of learning creative coding.
          The potential of cyberspace envisioned by web activist Aaron Swartz a few years earlier, as a place for
          “rather than retreating into a ‘cathedral’ of elite programmers, […] making the creation, distribution, and
          freedom of information as easy and frictionless as possible” was fully exploited by the Processing community
          with the release of the p5.js web editor, developed by Cassie Tarakajian in 2018. This move allowed to broaden
          Processing’s teaching and learning community, including high and middle school educational institutions that
          could now take advantage of the browser’s accessibility to introduce coding to younger students, without
          having to download and install software.

          <h3>2.2.3 Community: A Platform for Education</h3>
          Observing the evolution of the Processing environment from the local PDE to the more accessible browser,
          education has been proven central for the Processing platform. This pedagogical interest shaped the community
          that grew around the project, defining a dynamic that distanced itself from the general open source
          methodology based on the collaboration for interest. Open source software development has, classically, a
          communal aim of creating, through a collective mind, a more efficient piece of software. In the case of
          Processing, the community comes together in its joint mission of providing tools and platforms for sharing
          knowledge.
          Processing community’s expansion leaned on the generous and relentless work of individuals, who contributed to
          the growth of the project, always in the spirit of sharing learning opportunities:

          <p class="quote">The longest-running and most prominent effort is Sinan Ascioglu’s OpenProcessing, which
            recently launched a
            new interface that is compatible with p5.js sketches. Earlier initiatives include the Free Art Bureau’s
            Processing Cities initiatives to start user groups in cities around the world, Tom Carden and Karsten
            Schmidt’s Processing Hacks wiki, and Tom Carden’s blog aggregator. Early social media sites created
            community
            and energy around Processing through tags used within sites like Del.ici.ous and Flickr. OpenProcessing is
            going strong, but these other initiatives have changed as the web and the community has shifted.
          </p>

          Looking back at the project’s origins, the most influential figure who contributed to the expansion of
          Processing was—and still is—Dan Shiffman. Adjunct professor at ITP—a two-year Master’s program at Tisch School
          of the Arts, New York University—Shiffman joined the project right after his graduation at ITP in 2003.
          Processing was, at the time, a new tool for introducing programming to artists and designers. Within his
          research of unorthodox ways to teach programming and to unfold the potential of coding, Shiffman embraced
          Processing as an opportunity to develop new curricula at ITP. Wanting to experiment with reversed pedagogy
          (lectures at home; exercises in class) and foreseeing the potential of the web as an accessible platform for
          sharing pedagogical content, he started recording his lectures and sharing them with his student on Vimeo.
          These videos were not intended to become pedagogical material for a more extensive community, nor were they
          introductory tutorials to Processing; yet, they were accessible to anyone who wanted to discover the potential
          of the new coding language. The interest around Shiffman’s videos grew exponentially, revealing the promise of
          the web as a pedagogical platform and the potential of Processing as a pedagogical tool. Dan Shiffman became
          the most prominent ambassador of Processing, bringing together a community of people eager to learn and share
          the new tool.
          Born as an experiment, Shiffman’s videos created the building blocks for future development on the web. Hello
          Processing, a one-hour coding tutorial, was the precursor of Cassie Tarakajian’ web editor, featuring, for
          first time, a window for coding embedded in the browser. The YouTube channel The Coding Train was the most
          influential project that followed. With more than a million followers, The Coding Train is still the primary
          reference for learning creative coding, from the basics to more advanced features.
          The pedagogical implication of this phenomenon is, of course, non-negligible. Furthermore, The Coding Train
          contributed tremendously to building the Processing community. Without a doubt, part of the YouTube channel’s
          success is Dan Shiffman’s personality—an undeniably critical aspect in the construction of any community. The
          concept of accessibility, central to Processing development, brings with it the meaning of closeness to
          others. “Most essentially, Processing is about people. It’s about individuals and collective learning and
          exploration; it’s about sharing ideas and giving what you can.”

          <h2>2.3 Conclusion: From Platform to System of Values</h2>
          Considering the dramatic development of technology over the last twenty years, questioning the relevance of
          Processing as a digital tool in the contemporary software realm seems legitimate. By observing its trajectory
          and the steps undertaken by its creators, ambassadors, and community, it’s clear that Processing has evolved
          far beyond being a platform, to become a carrier of values.
          Initiated embedding visions of interdisciplinarity, collaboration and radical exploration in the field of the
          arts, Processing pursued its path regularly reassessing its core values. The flexibility of the coding
          language, the use of internet as an open and accessible sharing platform, and the focus on inclusive
          education, continue to contribute to shifting the meaning of “free open source” beyond software programming
          culture. Processing was able to bring together communities of non-coders, and in doing so, it opened
          programming to anyone interested in exploring alternative ways to approach design. Processing gave the
          opportunity to marginalized and unrepresented communities to exist outside the standardized and expensive
          design realm offered by mainstream tech infrastructures, continually embodying their spirit of openness and
          inclusion.
          In 2011, the creation of the Processing Foundation formalized the missions of its community, centered around
          values of diversity and inclusion: “The Processing Foundation is specifically invested in expanding the
          communities of technology and the arts to include and support those who have not had equal access because of
          their race, gender, class, sexuality, and/or disability.
        </div>
      </section>

      <section>
        <div class="oneCol">
          <h1>3. From Processing to (Graphic) Design</h1>
        </div>

        <div class="twoCol">
          In 2017, Casey Reas reassessed the core values of Processing, synthesized in the triad
          “access-community-free.” These principles have spread in the graphic design field, creating new territories in
          which design development focuses on inclusive and democratic methodologies.
          In the previous chapter, the three components, “language-environment-community,” provided a prism of analysis
          to explain the complexity of Processing as a platform. In this chapter, we exemplify the design shift,
          proposing a prism of observation based on Processing’s triad of values.
          Since the middle of the 2000s, graphic designers have questioned their position within the production chain
          and redefined their practice accordingly. Three patterns emerged, stressing Processing’s core values each in a
          different way. First, the rise of hybrid practices, which merged analog and digital tools, showed how the free
          open source sharing model and DIY methodologies had empowered accessibility and democratized design conception
          and production. Moreover, the influence of generative design and creative coding revealed a new path towards a
          design focusing on the “multiple,” as opposed to the “universal,” that opened conversations with diverse
          communities. Finally, the reappropriation of the publishing realm, leaning on free open source software and
          the web, subverted the graphic and editorial design’s chain of production, and provided new perspectives in
          these fields. These three axes are emblematic of the designers’ new stance in providing methodologies which
          now foster accessibility and inclusion, going against the standardization of design imposed by tech
          monopolies.


          <h2>3.1 Access: Hybrid Practices</h2>
          Inspired by the free open source and Do It Yourself (DIY) cultures, contemporary graphic designers and graphic
          design studios have embraced, over the last two decades, unorthodox project methodologies and, through the
          self-production of devices, have developed hybrid practices that mix analog, digital, and computational tools.
          After decades of staring at screens and claiming the death of paper and printing, the rise of these
          unconventional practices revealed how new technologies can improve graphic design esthetics and generate new
          opportunities for revamping traditional, and sometimes obsolete, printing methods. DIY, open source, and
          hacker cultures are actively providing valid methodologies to achieve this improvement. Today, we witness the
          conception of community and spaces built around objects of creation such as a RISO duplicator or a
          letterpress, set aside laser cutters, plotters, and 3d printers. “Hacking,” intended in its more contemporary
          meaning of “ingenious combination, or invention,” is crucial and provides relevant experimentations
          intersecting new technologies with traditional techniques. This unorthodox attitude embraces the lesson taught
          by Processing and restores the role of computers as tools serving the design practice, instead of controlling
          the practice itself. As a result, compelling combinations of realms, previously considered in opposition, are
          blooming, and altering the graphic design esthetics.

          <h3>3.1.1 Digital Fabrication and Traditional Printing Techniques</h3>
          By investigating the crossing of analog and digital processes, two patterns emerged as the most relevant in
          contemporary design practice, both aiming to emancipate designers from the esthetics’ normalization and
          commodification.
          The community grown around Processing and creative coding pursued its mission of developing digital
          easy-to-use tools and providing alternative software and platforms for the visual arts. Their work is often
          focused on building interactive devices and installations, frequently found on the frontier between art and
          design. The connection between creative coding and printing has been translated into the development of
          libraries that help transfer generated drawings on paper using mainly RISO duplicators, drawing machines such
          as pen-plotters, and eventually obsolete machines which have been hacked to add materiality to code-generated
          patterns. The results of these explorations, albeit sometimes facing issues of resolution and scale, have led
          to some fascinating processes. Louis Eveillard’s experimentations with his hacked embroider machine Tricodeur
          (a project developed in collaboration with 2roq and Sew&Laine in Bordeaux) and Licia He’s generated
          pen-plotted paintings both prove that young generations of artists and designers are susceptible to these
          opportunities and are, without inhibitions, dismantling the traditional separation between the space of
          screens and the one of studios.
          If emerging models connected to the realm of creative coding are growing within a territory where art and
          design intersect, digital fabrication has played a critical role in developing the professional graphic design
          practice, relying on DIY methodologies for the auto-production of tools from a professional production
          standpoint.
          Digital fabrication processes—intended as laser cutting and 3d printing techniques—have successfully
          contributed to giving new perspectives to traditional printing methods, and particularly to the letterpress.
          Since the middle of the 2010s, printers and designers have explored new production territories to expand their
          typefaces collections for letterpress printing. In 2016, the Berlin-based experimental letterpress workshop
          a98p had “tried it all: plexi, maple, pear, resin, magnesium, polymer, formica. CNC milling, 3D-printing,
          pantograph cutting, etched metal, vacuum-forming.” Between 2014 and 2017, the London-based letterpress printer
          and design studio New North Press developed compelling experimentations, such as the 3d printed typeface A23D
          or the laser cut hexagonal woodblocks system AHP Six, both projects aimed at capitalizing on new technologies
          to empower professional productions in traditional printing.
          Over the last few years, the development of affordable and valid desktop laser cutters and 3d printers has
          pushed the boundaries of graphic experimentation even further, allowing a disinhibited typographical approach,
          defying classical typesetting canons. The work of printers and designers like the British Thomas Mayo or the
          American Ryan Molloy are examples of how digital fabrication, particularly that of laser cutting, has been
          organically implemented in graphic design practice as an active part of the design process.
          Digital fabrication could legitimately be considered one of the main advancements of letterpress since the
          adoption of photopolymer plates in the 1980s; these have contributed to expanding the community of designers
          around letterpress, providing a renewal of tradition and the development of a new craft in opposition to
          over-digitalized contemporary design productions.

          <h3>3.1.2 The Open Source Sharing Model and the New Craft</h3>
          Within the context of this new craft, some cases have proven how the open source model of free exchange and
          collaboration is relevant to other fields such as traditional printing. In 2018, Martin Schneider and Dominik
          Schmitz published the plans of The Open Press Project, a “tiny 3D-printed etching press that will let you use
          these techniques outdoors, in your living room or small studio.” The two designers from Cologne, Germany,
          aware of the challenge of accessing an etching press, “wanted to give more people the option to use them for
          their art in places where printmaking was not possible before.” The project received extraordinary support,
          and a community proliferated around it, proving the relevance of enabling easy access to printing tools.
          New sharing opportunities brought by the internet offered a new dimension to the democratization of design
          foresaw by Enzo Mari in Autoprogettazione? Mari’s reappropriation of the objects and its conception and
          design, and the demystification of the industrial production are both empowered by the cyberspace and
          “electronic neighborhoods.”
          Looking from this perspective, the model of free exchange of knowledge for printing opportunities bloomed
          during the global health crisis in 2020. During the COVID19 pandemic, the portable letterpress Provisional
          Press proved the relevance of implementing DIY methodologies to create affordable tools to empower online
          teaching. Considering student’s financial and space restrictions, Steve Garst along with his wife Liz Garst,
          and in collaboration with Scott Moore of Moore Wood Type, designed a kit that could “be built by someone with
          little woodshop skills but access to a laser cutter.” This press offered “an inexpensive alternative that
          [could] act as a transitional press to enable students to make prints when they may not have access to a large
          steel press.” All plans and instructions are available online and, faithful to the open source free-exchange
          spirit, “free for anyone to use and modify as they experiment with building their own press.”
          These ideas resonate with the “modular, expandable, and customizable kit” proposed by Casey Reas and Ben Fry
          with Processing and have been transferred from digital to analog, from screen to print. The concept of
          accessibility is, thus, crucial: the auto-productive and auto-didactic approach inspired by the free open
          source sharing model fosters accessibility not only in the conception and production of design, but also for
          educational purposes, inside and outside of institutions.

          <h2>3.2 Community: Generative Identities</h2>
          Since the beginning of the 2000s, we have noticed a shift in corporate identity design towards visual
          identities called “flexible,” in which the classical pyramidal structure of companies’ language—from logo to
          applications—has been replaced by a multiplicity of signs communicating different facets of the brand. In
          post-WWII era, industrial production shifted from the manufacture of war supplies to commercial goods, and the
          importance of “branding” the companies to make them recognizable and sellable became central. Designers such
          as Massimo Vignelli and Paul Rand appropriated and applied, in the United States of the 1960s-1970s, the
          “design of systems,”— developed by figures of the Swiss Style such as Josef Müller-Brockmann—to shape
          commercial communication. The “Logo” (with a capital L) became the focus of corporate identity design with the
          mission of encapsulating the brand’s values as being timeless and universal. The classical corporate identity
          manual designed to set companies’ visual language, was built on one sign, spreading from top to bottom in a
          pyramid of applications. The logo at the top had to be respected as a dogma.
          At the beginning of the 2000s, the relationship with costumers radically changed due to the establishment of
          new channels of commercial communication, those mainly provided by the internet. Companies faced a newly
          fragmented market, in which larger communities—made up of different ages, origins, and statuses—had access to
          products and brands. The pyramidal communication with the “Logo” positioned at the top became obsolete and its
          values of timelessness and universality were questioned. Flexible identities established a system of
          communication based on variations and iterations of signs, bringing the brands’ visual language towards a
          horizontal, transversal and network-based system. The identity of the brand became a choral idiom, addressing
          a message of openness and flexible complexity to a broader and more diverse audience.

          <h3>3.2.1 From Flexible to Generative Identities</h3>
          In this context, generative design—visual creations generated with code—has conveyed interesting methodologies
          to create iterations of signs addressing larger communities and emphasizing the concept of “multiversal
          design.” Generative identities have been proven particularly relevant for cultural institutions, museums, and
          cities as a means to transmit sets of values and to open conversations with diverse communities, sometimes
          allowing for active participation in defining the entity’s visual language.
          The first emblematic example of generative design used to conceive flexible visual communication is the
          identity for Casa da Musica, a music hall in Porto, Portugal. Designed in 2007 by the New-Yorker graphic
          design studio Sagmeister & Walsh, the identity pioneered the idea of using creative coding to expand the
          design system, and this at a time when creative coding was gaining a reputation as a tool for mainly artistic
          expression. The identity systems’ inspiration came from Rem Khoolaas’s presentation of the building to the
          city of Porto, in which he defined the architecture as a “conglomeration of many layers of meanings.” The
          building naturally became the logo’s shape, representing this conglomeration. The logo design is based on
          different views of the building—north, south, east, west, top, and bottom— and its color palette varies,
          generated by a piece of software, the Logo Generator, created for the client. Scanning the image representing
          the current event or concert, the software can identify and apply to the logo a color palette in harmony with
          the image, and consistent with the event’s communication. Potentially, the instances of the logo are infinite,
          corresponding to each event and speaking to any public Casa da Musica would like to reach.
          Sagmeister & Walsh intended, with this work, to create an appealing and dynamic visual language which
          distanced communication from a “overrated sameness” and not specific to the idea of opening conversations and
          embracing communities. Nevertheless, their project unveiled new applications for creative coding within the
          graphic design practice, in foreseeing opportunities for inclusive “multiversal” design.
          Several notable projects following Casa da Musica, took advantage of these new opportunities. Studio Neue
          designed in 2010 the communication and visual identity for the peninsula of Nordkin, striving to increase the
          tourism in the area. Leaning on the concept of “The Mercy of the Elements” the studio was able to unite the
          different municipalities, overriding conflicts of interests, and proposed a logo generated by the changes of
          wind and temperature. These communal natural elements served to connect the peninsula’s different identities.
          That same year, for the celebration of its twenty-fifth anniversary, MIT entrusted the Berliner design studio
          TheGreeEyl and E Ron Kang, founder of Math Practice, with the redesign of its Media Lab’s visual identity. The
          identity wanted to manifest MIT’s spirit of transparency, mutual inspiration, and collaboration. Conceived
          with Processing, the visual language is composed of 45,000 possible algorithmic variations, stressing the
          diversity of the MIT community.

          <h3>3.2.2 Generative Design and Participatory Practices</h3>
          If previous cases were able to introduce creative coding as a tool for a more flexible communication, the most
          striking example, thus far, of generative identity used for participatory design is the Bologna City Branding.
          In response to the open call for the redesign of the Italian city’s communication, Michele Pastore and Matteo
          Bartoli proposed a graphic system that embraced Bologna’s plurality, aimed at illustrating the different
          realities of its inhabitants and tourists alike. To translate the richness and complexity of the city, the
          designers conceived an alphabet of geometrical elements, using the architectural archetypes of the city
          itself.
          The key element of the city’s identity is the online logo generator “ebologna.it,” which allows the citizens
          to participate in the creation of a visual language: “Through the online logo generator, anyone can become
          actor of the process of creation, adding a personal ‘fragment’ to the global identity of the city. The
          communication of Bologna is thus propelled in a new and unexplored dimension. This isn’t just a flexible
          identity system, it is—maybe for the first time—participatory.” According to 2019 data, 36,276 generated logos
          were shared online, 137 different logos were adopted by the municipality, and 183 generated logos were used by
          private companies on the territory.
          The idea of designing for the “multiverse” regains all its meaning: the community is involved in the process
          of communicating their city; citizens feel part of a whole, in respect of their identity and their voice; and
          the municipality opens dialogue and participation. Design thus becomes a tool fostering diversity and
          inclusion.

          <h2>3.3 Free: Independent Publishing</h2>
          Additional proposals for redefining the graphic designers’ position came from the independent publishing
          realm. Since the beginning of the 2000s, graphic designers, particularly in Europe, have questioned the
          editorial design practice and reappropriated printed objects as territories for research and experimentation.
          This approach is comparable to the artists’ emancipation, which occurred between the 1960s and the 1970s
          through the “democratic multiple” and made possible by newly accessibley and less expensive printing
          techniques. The printed object’s democratization experienced a rebirth in the contemporary graphic design
          scene, thanks to the advent of the internet. Graphic designers, mastering the editorial production’s chain
          from conception to production, began colonizing the publishing realm and adopted e-commerce to be set free
          from the economic and logistic burden of distribution. Furthermore, they embraced the web as an experimental
          publishing framework, including the use of cyberspace and free software as production tools, thus shaping
          unconventional visual expression.

          <h3>3.3.1 The Contemporary “Democratic Multiple”</h3>
          Relying on DIY methodologies for production and distribution, marginal micro-publishing realities have emerged
          over the last fifteen years, giving a new impetus to the independent publishing market and revamping the book
          as a democratic object of communication.
          The Swiss publishing project Rollo Press, founded at the end of 2007 by the graphic designer Urs Lehni,
          happened “accidentally” after Lehni decided to purchase a second-hand RISO duplicator on eBay. Since then,
          Rollo Press has served as a publishing house and printing platform for contemporary artists. Embracing the
          rough esthetic of the Risograph technique and, leaning on the graphic design skills of its founder, the
          micro-publishing house has already distributed more than sixty titles. Rollo Press is one of many cases
          showing how graphic designers have extended their role, from conception to production. Using their practice to
          support and distribute contemporary artists’ work, they have undertaken the roles of editor and publisher in
          addition to that of designer. This approach shifted the “democratic multiple” from a means of self-expression
          to a tool for collaboration and curatorship.
          In some cases, independent editorial entities—once just experiments—have now established themselves as
          realities and have grown to become references in the field of publishing “by graphic designers, for graphic
          designers.” The publishing houses B42 in France and Unit Edition in the UK are striking examples of this
          dynamic. Both were founded by accomplished graphic design studios—respectively by DeValence in 2008 and by
          Spin Studio alongside Adrian Shaughnessy in 2009—and have developed extended catalogs of books exploring
          different facets of the graphic design practice. Although B42 focuses on critical texts, and Unit Edition on
          graphic design productions, there are common threads to their practices, particularly in term of their efforts
          to present “subjects that are either neglected or ignored by mainstream publishers.” They also both
          capitalized on online distribution to create a sustainable business model. Their endeavors have contributed to
          the democratization of the graphic design culture, without compromising on the quality of their publications.

          <h3>3.3.2 Independent Tools for Independent Publishing</h3>
          A more radical approach towards an uncompromised practice came at the beginning of the 2000s from entities
          committed to the Free/Libre Open Source Software (FLOSS).
          Founded in Brussels in 2006, Open Source Publishing (OSP) is one of the first graphic design collectives that
          committed to exclusively using FLOSS as a tool for a work’s production, and free open license for publication.
          Convinced of the limitation of dominant software’s interfaces (such as Adobe) often restricting the user to
          standardized design gestures, they questioned the influence of digital tools on their practice and looked for
          alternative graphic design studios’ models. Inspired by open source software development, they also conceived
          alternative tools for graphic design to facilitate collaboration. In 2014, they initiated the free software
          Visual Culture that allows keeping track, visualizing, and sharing the visual history of in-progress files
          without losing the current version of the work. Inspired by the Git branching model used in open source
          software development they expanded its collaborative methodology to visual practices as graphic design. Visual
          Culture became thus an invitation for collaborations between professionals. Questioning the economic
          dependence on mainstream software, Open Source Publishing challenges graphic designers and educational
          institutions to act and dismantle this paradigm.
          Responding to OSP’s invitation, Raphaël Bastide and Sarah Garcin started in 2017 PrePostPrint, a platform
          gathering experimental editorial projects conceived using FLOSS. Focusing on publishing, the French designers’
          ambition is to promote graphic design explorations based on unorthodox design methodologies relying on
          non-traditional and affordable tools of production. Using the web as an alternative platform for creating
          layouts using HTML and CSS coding languages, they propose a production chain that allows the designer’s
          complete autonomy from traditional software. Their practice embraced the spirit of sharing knowledge through
          organizing workshops in schools, giving lectures, and gathering information about people, projects, and
          studios working with similar preoccupations.
          Open Source Publishing and PrePostPrint are compelling examples of radical propositions to stand up against
          the tech giants’ monopolies and regain autonomy and freedom in the graphic design practice. Furthermore, this
          radicality has undeniably generated an array of original visual propositions, marking a break from
          conventional and standardized results obtained with mainstream digital tools. Nevertheless, regaining autonomy
          using the free software seems still complicated to implement on a regular basis in a graphic design practice,
          which often remains chained to a market ruled by standardized tools. Furthermore, the functionalities of
          unorthodox software such as Visual Culture or the possibility of web-to-print practices are still a mystery
          for the average designer, who is more at ease faced with Adobe interfaces than before two lines of code. Can
          this radical approach be implemented in everyday design practice? Open Source Publishing proposes the
          following:
          <p class="quote">How could we dismantle the dominant logic [of closed software] if we do not react? In the
            closed environment
            in which the students are trained for their own alienation, schools have an essential role to play to change
            the world promised by the software industry. We dream of schools dedicating their budgets to free software
            creation, instructors’ training, and studio materials; schools that would build and redistribute free
            software, using it—why not?—as a means of communication. How many failures do we need to open our eyes,
            finally?
          </p>

          <h2>3.4 Conclusion: Towards a Practice Renewal</h2>
          Now that graphic design is tightly interwoven with tech giants’ infrastructures, designers struggle to
          identify alternative processes and tools to regain independence in their practice. In response to mainstream
          tools and standardized visual patterns imposed by the market’s rules, some designers have embraced the values
          promoted by Processing and found alternative processes to differentiate their work from normalized dynamics
          and shift their practice towards a more inclusive and responsible design.
          Nevertheless, each proposition has been shown to partially tackle the multi-faceted design dilemma: the
          practice is so entangled with tools and culture provided by the tech monopolies that a radical approach to
          extract the designers from this reality does not seem to solve the tension between original visual research
          and commercial production. To explore new trajectories for a practice renewal, graphic designers can, thus,
          take advantage of a multiplicity of tools and a combination of approaches belonging to different and sometimes
          divergent realms in the effort of apprehending the paradox of the design practice and compromising with it.
          Furthermore, as Processing has shown with its trajectory, and Open Source Publishing reiterated in their
          interview with Strabic, pedagogy is key for dismantling the dominant dynamic of the monopolies. Educational
          institutions have an essential role in identifying new methodologies for sharing knowledge and showing
          alternative frameworks of production.
        </div>
      </section>

      <section>
        <div class="oneCol">
          <h1>Conclusion</h1>
        </div>

        <div class="twoCol">
          Drastically reformed by the mainstream digital tools that arose at the end of the twentieth century, the
          graphic design practice is experiencing a critical methodological crisis. The armada of ready-made tools
          provided by companies shaped within the Silicon Valley paradox has ruled the graphic design field, trapping
          graphic designers in an inextricable dilemma. The intuitive interfaces, software, and design components
          provided by Apple, Adobe, and Google allowed “bringing computers to the people,” yet were responsible for
          commodifying the design tools and culture. Graphic designers are now tugged between the necessity of being
          part of a market and exiting the standardized visual pattern induced by the tech monopolies.
          Easy access to computers and software weakened the creative process, shifting the profession towards a
          technical skills compilation, emptied of critical skills. Furthermore, in the effort of conquering a broader
          market, the “access” provided by tech infrastructures focused on giving the visual keys to communicate and
          interact with the computer, forgetting “affordability” as its critical connotation. Mainstream digital tools
          are expensive and hardly affordable by independent designers, consolidating graphic design as a practice for
          privileged communities.

          In this context, two forces have counter powered this trend: radical design research and the free open source
          culture. Observing MIT’s trajectory of the end of the twentieth century, we have identified the roots of these
          two counterpowers in its research laboratories. The hackers’ culture—that have informed the open source
          sharing methods—and Muriel Cooper and John Maeda’s radical approach have fused into Casey Reas and Ben Fry’s
          project Processing. A pivotal event for the design field, Processing immensely contributed to reappropriating
          the graphic design practice as a critical process and redefining the graphic designers’ position, shifting the
          practice towards a design of diversity and inclusion. Processing has shown how, changing the paradigm of
          production and distribution, designers can integrate a prism of observation based on “multiversality” instead
          of “universality.” Furthermore, “accessibility” retrieves its economic, social, and political connotation, and
          the free and open access to digital tools and the free framework for sharing and learning become fundamental.
          By giving access to design tools to unprivileged communities, Processing fosters democratization of design
          instead of its pauperization.

          Some designers have invested in Processing as a tool and a system of values, reassessing their gaze on design
          production and integrating the social and political dimension as central. New methodologies, including the
          hybridization of production tools, DIY distribution methods, participatory generative design, and the use of
          cyberspace as a free framework, were invested as valid alternatives in their practice renewal.
          However, these approaches are still exceptions. In contemporary society, being a designer remains a privilege,
          and designing is still inherently perceived as an act of exclusion. When we design, we work to solve specific
          problems, focusing on specific audiences, responding to specific briefs of specific clients. So, how can
          designers work actively to define a more responsible and inclusive practice?
          Throughout this thesis, we have opposed start-up and free open source cultures, identifying polarities that
          arose from this dichotomy: close versus open; universal versus multiversal; centralized versus decentralized.
          How should the designers position themselves tugged between these opposite forces? This thesis proposes to
          refuse any alliance to a radical stance. The designer can create flexible responses to design questions by
          shifting the cursors between opposite dualities and regularly inspecting their work and position. The
          designer’s practice can be enriched by different combinations of values, becoming modulable, dynamic, and
          adjusted for each project.
          Who are we designing for? Who are we forgetting? Who are we excluding intentionally or unintentionally? How
          can we force the cursor towards one specific direction? These are some of the questions that may help
          designers navigate their practice. This proposition is not exhaustive, and the list of polarities can be
          extended and completed.
          Moreover, to enhance this proposition, it is paramount to focus on the intersection of “accessibility” and
          “inclusion.” As shown throughout this thesis, “accessibility” can be legitimately used to describe Apple and
          Adobe interfaces (user friendly, but not affordable), as well as a source code (free of use, but not easily
          understandable for non-coders). These two objects are both accessible but, considering the economic
          connotation of the term, represent different levels of inclusion. The crossing between the term
          “accessibility” and “inclusion” unfolds a semiotic territory that designers can explore to better visualize
          their project’s stance.
          To integrate in their practice a more responsible posture, designers are invited to get inspired by the
          Processing community that has been able, throughout the years, to regularly reassess their focus and shift
          from a position of radical research to open and flexible inclusivity. Designers must grow in the same
          direction. A paradox is embedded in designers’ professional practice, and this dilemma cannot and does not
          have to be solved. Yet, it should be apprehended. As a privileged community, designers have the responsibility
          of developing and breeding awareness and critical thinking for a more inclusive design.
          Moreover, Art and Design educational institutions are also responsible for integrating this prism in their
          teaching to equip students—professionals-to-be—with the critical eye necessary to confront the contemporary
          design dilemma. Some independent pedagogical projects have successfully created diverse and inclusive spaces
          for critical thinking and responsible creation. The Processing Foundation has developed an educational section
          gathering pedagogical material free to use: “Rather than endorse a specific curriculum, we’ve engaged with a
          variety of educators from our community, ranging from K12 teachers, to folks who lead workshops at
          hackerspaces, to university professors in interdisciplinary departments. We’ve asked them to share their
          teaching materials here, which anyone can use.”
          Institutions cannot ignore the major shift that occurred in the design practice and, following the example of
          Processing, must learn from the free open source culture communities and integrate methodologies based on
          openness, decentralization, and horizontal collaboration.


        </div>
      </section>


    </div>
    </section>
  </div>
  </div>




  <!-- <img class="mon-image" src="images/mon-image.jpg"/> -->

</body>

</html>